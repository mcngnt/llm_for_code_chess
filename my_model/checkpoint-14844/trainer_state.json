{
  "best_global_step": 14844,
  "best_metric": 2.3823723793029785,
  "best_model_checkpoint": "./my_model/checkpoint-14844",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 14844,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.006736728644570197,
      "grad_norm": 2.949559211730957,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 6.9437,
      "step": 100
    },
    {
      "epoch": 0.013473457289140393,
      "grad_norm": 2.7113895416259766,
      "learning_rate": 6.700336700336701e-05,
      "loss": 6.2738,
      "step": 200
    },
    {
      "epoch": 0.02021018593371059,
      "grad_norm": 1.879023790359497,
      "learning_rate": 0.00010067340067340068,
      "loss": 5.6411,
      "step": 300
    },
    {
      "epoch": 0.026946914578280787,
      "grad_norm": 1.3534733057022095,
      "learning_rate": 0.00013434343434343436,
      "loss": 5.0801,
      "step": 400
    },
    {
      "epoch": 0.03368364322285099,
      "grad_norm": 0.7398509383201599,
      "learning_rate": 0.00016801346801346802,
      "loss": 4.6263,
      "step": 500
    },
    {
      "epoch": 0.04042037186742118,
      "grad_norm": 1.206822156906128,
      "learning_rate": 0.00020168350168350168,
      "loss": 4.4244,
      "step": 600
    },
    {
      "epoch": 0.04715710051199138,
      "grad_norm": 1.3391135931015015,
      "learning_rate": 0.00023535353535353534,
      "loss": 4.2601,
      "step": 700
    },
    {
      "epoch": 0.05389382915656157,
      "grad_norm": 0.6792125105857849,
      "learning_rate": 0.000269023569023569,
      "loss": 4.1262,
      "step": 800
    },
    {
      "epoch": 0.060630557801131774,
      "grad_norm": 0.8416737914085388,
      "learning_rate": 0.0003026936026936027,
      "loss": 3.985,
      "step": 900
    },
    {
      "epoch": 0.06736728644570197,
      "grad_norm": 0.840650737285614,
      "learning_rate": 0.0003363636363636364,
      "loss": 3.8628,
      "step": 1000
    },
    {
      "epoch": 0.07410401509027216,
      "grad_norm": 1.1008151769638062,
      "learning_rate": 0.00037003367003367007,
      "loss": 3.7602,
      "step": 1100
    },
    {
      "epoch": 0.08084074373484236,
      "grad_norm": 0.9099698066711426,
      "learning_rate": 0.00040370370370370375,
      "loss": 3.6583,
      "step": 1200
    },
    {
      "epoch": 0.08757747237941256,
      "grad_norm": 1.1661803722381592,
      "learning_rate": 0.0004373737373737374,
      "loss": 3.5708,
      "step": 1300
    },
    {
      "epoch": 0.09431420102398276,
      "grad_norm": 1.098409652709961,
      "learning_rate": 0.0004710437710437711,
      "loss": 3.5049,
      "step": 1400
    },
    {
      "epoch": 0.10105092966855295,
      "grad_norm": 0.9841771125793457,
      "learning_rate": 0.0004994760086832847,
      "loss": 3.4264,
      "step": 1500
    },
    {
      "epoch": 0.10778765831312315,
      "grad_norm": 1.0167489051818848,
      "learning_rate": 0.0004957332135638895,
      "loss": 3.3664,
      "step": 1600
    },
    {
      "epoch": 0.11452438695769335,
      "grad_norm": 1.1554077863693237,
      "learning_rate": 0.0004919904184444944,
      "loss": 3.3108,
      "step": 1700
    },
    {
      "epoch": 0.12126111560226355,
      "grad_norm": 0.979770839214325,
      "learning_rate": 0.0004882476233250992,
      "loss": 3.2494,
      "step": 1800
    },
    {
      "epoch": 0.12799784424683375,
      "grad_norm": 1.0463343858718872,
      "learning_rate": 0.000484504828205704,
      "loss": 3.2035,
      "step": 1900
    },
    {
      "epoch": 0.13473457289140395,
      "grad_norm": 0.9727223515510559,
      "learning_rate": 0.0004807620330863089,
      "loss": 3.1699,
      "step": 2000
    },
    {
      "epoch": 0.14147130153597412,
      "grad_norm": 1.117917537689209,
      "learning_rate": 0.0004770192379669137,
      "loss": 3.1306,
      "step": 2100
    },
    {
      "epoch": 0.14820803018054432,
      "grad_norm": 1.0299581289291382,
      "learning_rate": 0.00047327644284751854,
      "loss": 3.0979,
      "step": 2200
    },
    {
      "epoch": 0.15494475882511452,
      "grad_norm": 1.2050291299819946,
      "learning_rate": 0.00046953364772812337,
      "loss": 3.0788,
      "step": 2300
    },
    {
      "epoch": 0.16168148746968472,
      "grad_norm": 1.0783114433288574,
      "learning_rate": 0.00046579085260872825,
      "loss": 3.0464,
      "step": 2400
    },
    {
      "epoch": 0.16841821611425492,
      "grad_norm": 1.0704172849655151,
      "learning_rate": 0.000462048057489333,
      "loss": 3.0222,
      "step": 2500
    },
    {
      "epoch": 0.17515494475882512,
      "grad_norm": 1.0677658319473267,
      "learning_rate": 0.00045830526236993784,
      "loss": 3.0047,
      "step": 2600
    },
    {
      "epoch": 0.18189167340339532,
      "grad_norm": 0.962883472442627,
      "learning_rate": 0.0004545624672505427,
      "loss": 2.9818,
      "step": 2700
    },
    {
      "epoch": 0.18862840204796552,
      "grad_norm": 1.1326391696929932,
      "learning_rate": 0.00045081967213114754,
      "loss": 2.9614,
      "step": 2800
    },
    {
      "epoch": 0.1953651306925357,
      "grad_norm": 1.0864375829696655,
      "learning_rate": 0.00044707687701175236,
      "loss": 2.9467,
      "step": 2900
    },
    {
      "epoch": 0.2021018593371059,
      "grad_norm": 1.0365490913391113,
      "learning_rate": 0.00044333408189235724,
      "loss": 2.9371,
      "step": 3000
    },
    {
      "epoch": 0.2088385879816761,
      "grad_norm": 1.2034568786621094,
      "learning_rate": 0.00043959128677296207,
      "loss": 2.9212,
      "step": 3100
    },
    {
      "epoch": 0.2155753166262463,
      "grad_norm": 0.9566541314125061,
      "learning_rate": 0.0004358484916535669,
      "loss": 2.892,
      "step": 3200
    },
    {
      "epoch": 0.2223120452708165,
      "grad_norm": 1.173039197921753,
      "learning_rate": 0.00043210569653417177,
      "loss": 2.8834,
      "step": 3300
    },
    {
      "epoch": 0.2290487739153867,
      "grad_norm": 1.0252246856689453,
      "learning_rate": 0.0004283629014147766,
      "loss": 2.8697,
      "step": 3400
    },
    {
      "epoch": 0.2357855025599569,
      "grad_norm": 1.052574634552002,
      "learning_rate": 0.0004246201062953814,
      "loss": 2.8488,
      "step": 3500
    },
    {
      "epoch": 0.2425222312045271,
      "grad_norm": 0.9854791760444641,
      "learning_rate": 0.0004208773111759862,
      "loss": 2.8316,
      "step": 3600
    },
    {
      "epoch": 0.24925895984909727,
      "grad_norm": 0.9913018345832825,
      "learning_rate": 0.00041713451605659106,
      "loss": 2.8421,
      "step": 3700
    },
    {
      "epoch": 0.2559956884936675,
      "grad_norm": 1.0729914903640747,
      "learning_rate": 0.0004133917209371959,
      "loss": 2.8206,
      "step": 3800
    },
    {
      "epoch": 0.2627324171382377,
      "grad_norm": 1.061929702758789,
      "learning_rate": 0.0004096489258178007,
      "loss": 2.8179,
      "step": 3900
    },
    {
      "epoch": 0.2694691457828079,
      "grad_norm": 0.9991409182548523,
      "learning_rate": 0.0004059061306984056,
      "loss": 2.8001,
      "step": 4000
    },
    {
      "epoch": 0.27620587442737804,
      "grad_norm": 1.0808279514312744,
      "learning_rate": 0.0004021633355790104,
      "loss": 2.7839,
      "step": 4100
    },
    {
      "epoch": 0.28294260307194824,
      "grad_norm": 1.0009995698928833,
      "learning_rate": 0.00039842054045961524,
      "loss": 2.7886,
      "step": 4200
    },
    {
      "epoch": 0.28967933171651844,
      "grad_norm": 1.0439164638519287,
      "learning_rate": 0.0003946777453402201,
      "loss": 2.7815,
      "step": 4300
    },
    {
      "epoch": 0.29641606036108864,
      "grad_norm": 1.0213278532028198,
      "learning_rate": 0.00039093495022082494,
      "loss": 2.7726,
      "step": 4400
    },
    {
      "epoch": 0.30315278900565884,
      "grad_norm": 1.0496894121170044,
      "learning_rate": 0.00038719215510142976,
      "loss": 2.7638,
      "step": 4500
    },
    {
      "epoch": 0.30988951765022904,
      "grad_norm": 1.1082305908203125,
      "learning_rate": 0.00038344935998203464,
      "loss": 2.7628,
      "step": 4600
    },
    {
      "epoch": 0.31662624629479924,
      "grad_norm": 1.0811814069747925,
      "learning_rate": 0.0003797065648626394,
      "loss": 2.7465,
      "step": 4700
    },
    {
      "epoch": 0.32336297493936944,
      "grad_norm": 0.9420023560523987,
      "learning_rate": 0.00037596376974324423,
      "loss": 2.745,
      "step": 4800
    },
    {
      "epoch": 0.33009970358393964,
      "grad_norm": 1.0158002376556396,
      "learning_rate": 0.00037222097462384906,
      "loss": 2.7334,
      "step": 4900
    },
    {
      "epoch": 0.33683643222850984,
      "grad_norm": 0.9499284625053406,
      "learning_rate": 0.00036847817950445394,
      "loss": 2.73,
      "step": 5000
    },
    {
      "epoch": 0.34357316087308004,
      "grad_norm": 0.9520103335380554,
      "learning_rate": 0.00036473538438505876,
      "loss": 2.7251,
      "step": 5100
    },
    {
      "epoch": 0.35030988951765024,
      "grad_norm": 0.985798716545105,
      "learning_rate": 0.0003609925892656636,
      "loss": 2.7222,
      "step": 5200
    },
    {
      "epoch": 0.35704661816222044,
      "grad_norm": 1.0608407258987427,
      "learning_rate": 0.00035724979414626846,
      "loss": 2.7117,
      "step": 5300
    },
    {
      "epoch": 0.36378334680679064,
      "grad_norm": 1.0575584173202515,
      "learning_rate": 0.0003535069990268733,
      "loss": 2.7089,
      "step": 5400
    },
    {
      "epoch": 0.37052007545136084,
      "grad_norm": 1.1140059232711792,
      "learning_rate": 0.0003497642039074781,
      "loss": 2.6987,
      "step": 5500
    },
    {
      "epoch": 0.37725680409593104,
      "grad_norm": 1.0585074424743652,
      "learning_rate": 0.000346021408788083,
      "loss": 2.7003,
      "step": 5600
    },
    {
      "epoch": 0.3839935327405012,
      "grad_norm": 1.076384425163269,
      "learning_rate": 0.0003422786136686878,
      "loss": 2.6882,
      "step": 5700
    },
    {
      "epoch": 0.3907302613850714,
      "grad_norm": 1.0792986154556274,
      "learning_rate": 0.0003385358185492926,
      "loss": 2.6877,
      "step": 5800
    },
    {
      "epoch": 0.3974669900296416,
      "grad_norm": 0.9311999678611755,
      "learning_rate": 0.00033479302342989746,
      "loss": 2.6751,
      "step": 5900
    },
    {
      "epoch": 0.4042037186742118,
      "grad_norm": 1.0223934650421143,
      "learning_rate": 0.0003310502283105023,
      "loss": 2.6757,
      "step": 6000
    },
    {
      "epoch": 0.410940447318782,
      "grad_norm": 1.0599430799484253,
      "learning_rate": 0.0003273074331911071,
      "loss": 2.6688,
      "step": 6100
    },
    {
      "epoch": 0.4176771759633522,
      "grad_norm": 1.102354645729065,
      "learning_rate": 0.00032356463807171193,
      "loss": 2.6741,
      "step": 6200
    },
    {
      "epoch": 0.4244139046079224,
      "grad_norm": 1.1215225458145142,
      "learning_rate": 0.0003198218429523168,
      "loss": 2.6539,
      "step": 6300
    },
    {
      "epoch": 0.4311506332524926,
      "grad_norm": 1.063836693763733,
      "learning_rate": 0.00031607904783292163,
      "loss": 2.6593,
      "step": 6400
    },
    {
      "epoch": 0.4378873618970628,
      "grad_norm": 1.120821475982666,
      "learning_rate": 0.00031233625271352646,
      "loss": 2.6542,
      "step": 6500
    },
    {
      "epoch": 0.444624090541633,
      "grad_norm": 1.0779836177825928,
      "learning_rate": 0.00030859345759413133,
      "loss": 2.6479,
      "step": 6600
    },
    {
      "epoch": 0.4513608191862032,
      "grad_norm": 1.0873311758041382,
      "learning_rate": 0.00030485066247473616,
      "loss": 2.6429,
      "step": 6700
    },
    {
      "epoch": 0.4580975478307734,
      "grad_norm": 1.070394515991211,
      "learning_rate": 0.000301107867355341,
      "loss": 2.6513,
      "step": 6800
    },
    {
      "epoch": 0.4648342764753436,
      "grad_norm": 1.016154408454895,
      "learning_rate": 0.00029736507223594586,
      "loss": 2.6414,
      "step": 6900
    },
    {
      "epoch": 0.4715710051199138,
      "grad_norm": 1.019770622253418,
      "learning_rate": 0.00029362227711655063,
      "loss": 2.6412,
      "step": 7000
    },
    {
      "epoch": 0.478307733764484,
      "grad_norm": 1.0607998371124268,
      "learning_rate": 0.00028987948199715545,
      "loss": 2.6383,
      "step": 7100
    },
    {
      "epoch": 0.4850444624090542,
      "grad_norm": 1.0282959938049316,
      "learning_rate": 0.00028613668687776033,
      "loss": 2.6338,
      "step": 7200
    },
    {
      "epoch": 0.49178119105362433,
      "grad_norm": 1.0992473363876343,
      "learning_rate": 0.00028239389175836515,
      "loss": 2.6269,
      "step": 7300
    },
    {
      "epoch": 0.49851791969819453,
      "grad_norm": 0.9973458647727966,
      "learning_rate": 0.00027865109663897,
      "loss": 2.6293,
      "step": 7400
    },
    {
      "epoch": 0.5052546483427648,
      "grad_norm": 1.0671285390853882,
      "learning_rate": 0.0002749083015195748,
      "loss": 2.622,
      "step": 7500
    },
    {
      "epoch": 0.511991376987335,
      "grad_norm": 1.0863691568374634,
      "learning_rate": 0.0002711655064001797,
      "loss": 2.6178,
      "step": 7600
    },
    {
      "epoch": 0.5187281056319052,
      "grad_norm": 1.0242542028427124,
      "learning_rate": 0.0002674227112807845,
      "loss": 2.6144,
      "step": 7700
    },
    {
      "epoch": 0.5254648342764754,
      "grad_norm": 1.0762910842895508,
      "learning_rate": 0.00026367991616138933,
      "loss": 2.6107,
      "step": 7800
    },
    {
      "epoch": 0.5322015629210456,
      "grad_norm": 1.0711572170257568,
      "learning_rate": 0.0002599371210419942,
      "loss": 2.6074,
      "step": 7900
    },
    {
      "epoch": 0.5389382915656158,
      "grad_norm": 0.9785981774330139,
      "learning_rate": 0.00025619432592259903,
      "loss": 2.6036,
      "step": 8000
    },
    {
      "epoch": 0.5456750202101859,
      "grad_norm": 1.0030876398086548,
      "learning_rate": 0.0002524515308032038,
      "loss": 2.6097,
      "step": 8100
    },
    {
      "epoch": 0.5524117488547561,
      "grad_norm": 1.1251627206802368,
      "learning_rate": 0.0002487087356838087,
      "loss": 2.6075,
      "step": 8200
    },
    {
      "epoch": 0.5591484774993263,
      "grad_norm": 1.0616639852523804,
      "learning_rate": 0.0002449659405644135,
      "loss": 2.5976,
      "step": 8300
    },
    {
      "epoch": 0.5658852061438965,
      "grad_norm": 1.0907671451568604,
      "learning_rate": 0.00024122314544501832,
      "loss": 2.5984,
      "step": 8400
    },
    {
      "epoch": 0.5726219347884667,
      "grad_norm": 1.0472058057785034,
      "learning_rate": 0.00023748035032562318,
      "loss": 2.5911,
      "step": 8500
    },
    {
      "epoch": 0.5793586634330369,
      "grad_norm": 1.06373929977417,
      "learning_rate": 0.00023373755520622803,
      "loss": 2.59,
      "step": 8600
    },
    {
      "epoch": 0.5860953920776071,
      "grad_norm": 1.1172975301742554,
      "learning_rate": 0.00022999476008683285,
      "loss": 2.5868,
      "step": 8700
    },
    {
      "epoch": 0.5928321207221773,
      "grad_norm": 1.0827640295028687,
      "learning_rate": 0.0002262519649674377,
      "loss": 2.587,
      "step": 8800
    },
    {
      "epoch": 0.5995688493667475,
      "grad_norm": 0.9993425607681274,
      "learning_rate": 0.00022250916984804253,
      "loss": 2.5798,
      "step": 8900
    },
    {
      "epoch": 0.6063055780113177,
      "grad_norm": 1.104277491569519,
      "learning_rate": 0.00021876637472864735,
      "loss": 2.5858,
      "step": 9000
    },
    {
      "epoch": 0.6130423066558879,
      "grad_norm": 1.0455870628356934,
      "learning_rate": 0.0002150235796092522,
      "loss": 2.5771,
      "step": 9100
    },
    {
      "epoch": 0.6197790353004581,
      "grad_norm": 1.117649793624878,
      "learning_rate": 0.00021128078448985702,
      "loss": 2.5733,
      "step": 9200
    },
    {
      "epoch": 0.6265157639450283,
      "grad_norm": 1.0353636741638184,
      "learning_rate": 0.00020753798937046187,
      "loss": 2.5747,
      "step": 9300
    },
    {
      "epoch": 0.6332524925895985,
      "grad_norm": 1.117082953453064,
      "learning_rate": 0.00020379519425106673,
      "loss": 2.5696,
      "step": 9400
    },
    {
      "epoch": 0.6399892212341687,
      "grad_norm": 1.0568095445632935,
      "learning_rate": 0.00020005239913167152,
      "loss": 2.5638,
      "step": 9500
    },
    {
      "epoch": 0.6467259498787389,
      "grad_norm": 1.021930456161499,
      "learning_rate": 0.00019630960401227637,
      "loss": 2.5759,
      "step": 9600
    },
    {
      "epoch": 0.6534626785233091,
      "grad_norm": 1.019407868385315,
      "learning_rate": 0.0001925668088928812,
      "loss": 2.567,
      "step": 9700
    },
    {
      "epoch": 0.6601994071678793,
      "grad_norm": 1.0612914562225342,
      "learning_rate": 0.00018882401377348605,
      "loss": 2.5607,
      "step": 9800
    },
    {
      "epoch": 0.6669361358124495,
      "grad_norm": 1.09257173538208,
      "learning_rate": 0.0001850812186540909,
      "loss": 2.5636,
      "step": 9900
    },
    {
      "epoch": 0.6736728644570197,
      "grad_norm": 1.035231351852417,
      "learning_rate": 0.0001813384235346957,
      "loss": 2.5603,
      "step": 10000
    },
    {
      "epoch": 0.6804095931015899,
      "grad_norm": 0.9986576437950134,
      "learning_rate": 0.00017759562841530055,
      "loss": 2.5586,
      "step": 10100
    },
    {
      "epoch": 0.6871463217461601,
      "grad_norm": 0.9891303777694702,
      "learning_rate": 0.0001738528332959054,
      "loss": 2.5477,
      "step": 10200
    },
    {
      "epoch": 0.6938830503907303,
      "grad_norm": 1.12174391746521,
      "learning_rate": 0.00017011003817651022,
      "loss": 2.5434,
      "step": 10300
    },
    {
      "epoch": 0.7006197790353005,
      "grad_norm": 1.0154720544815063,
      "learning_rate": 0.00016636724305711507,
      "loss": 2.5549,
      "step": 10400
    },
    {
      "epoch": 0.7073565076798707,
      "grad_norm": 1.0691561698913574,
      "learning_rate": 0.0001626244479377199,
      "loss": 2.5457,
      "step": 10500
    },
    {
      "epoch": 0.7140932363244409,
      "grad_norm": 1.0660181045532227,
      "learning_rate": 0.00015888165281832472,
      "loss": 2.551,
      "step": 10600
    },
    {
      "epoch": 0.7208299649690111,
      "grad_norm": 1.0809767246246338,
      "learning_rate": 0.00015513885769892957,
      "loss": 2.5503,
      "step": 10700
    },
    {
      "epoch": 0.7275666936135813,
      "grad_norm": 1.0420881509780884,
      "learning_rate": 0.0001513960625795344,
      "loss": 2.5452,
      "step": 10800
    },
    {
      "epoch": 0.7343034222581515,
      "grad_norm": 1.094761610031128,
      "learning_rate": 0.00014765326746013925,
      "loss": 2.5494,
      "step": 10900
    },
    {
      "epoch": 0.7410401509027217,
      "grad_norm": 1.020210862159729,
      "learning_rate": 0.00014391047234074407,
      "loss": 2.5372,
      "step": 11000
    },
    {
      "epoch": 0.7477768795472919,
      "grad_norm": 1.0537554025650024,
      "learning_rate": 0.0001401676772213489,
      "loss": 2.5419,
      "step": 11100
    },
    {
      "epoch": 0.7545136081918621,
      "grad_norm": 1.0310527086257935,
      "learning_rate": 0.00013642488210195374,
      "loss": 2.5415,
      "step": 11200
    },
    {
      "epoch": 0.7612503368364322,
      "grad_norm": 1.0340486764907837,
      "learning_rate": 0.00013268208698255857,
      "loss": 2.539,
      "step": 11300
    },
    {
      "epoch": 0.7679870654810024,
      "grad_norm": 1.055877447128296,
      "learning_rate": 0.00012893929186316342,
      "loss": 2.531,
      "step": 11400
    },
    {
      "epoch": 0.7747237941255726,
      "grad_norm": 1.057147741317749,
      "learning_rate": 0.00012519649674376827,
      "loss": 2.5358,
      "step": 11500
    },
    {
      "epoch": 0.7814605227701428,
      "grad_norm": 1.0900800228118896,
      "learning_rate": 0.00012145370162437308,
      "loss": 2.5272,
      "step": 11600
    },
    {
      "epoch": 0.788197251414713,
      "grad_norm": 1.0708444118499756,
      "learning_rate": 0.00011771090650497792,
      "loss": 2.5307,
      "step": 11700
    },
    {
      "epoch": 0.7949339800592832,
      "grad_norm": 1.1330311298370361,
      "learning_rate": 0.00011396811138558275,
      "loss": 2.5347,
      "step": 11800
    },
    {
      "epoch": 0.8016707087038534,
      "grad_norm": 1.060020923614502,
      "learning_rate": 0.00011022531626618759,
      "loss": 2.5399,
      "step": 11900
    },
    {
      "epoch": 0.8084074373484236,
      "grad_norm": 1.1403871774673462,
      "learning_rate": 0.00010648252114679243,
      "loss": 2.5245,
      "step": 12000
    },
    {
      "epoch": 0.8151441659929938,
      "grad_norm": 1.0075606107711792,
      "learning_rate": 0.00010273972602739725,
      "loss": 2.5212,
      "step": 12100
    },
    {
      "epoch": 0.821880894637564,
      "grad_norm": 0.9542789459228516,
      "learning_rate": 9.89969309080021e-05,
      "loss": 2.5258,
      "step": 12200
    },
    {
      "epoch": 0.8286176232821342,
      "grad_norm": 1.0688530206680298,
      "learning_rate": 9.525413578860694e-05,
      "loss": 2.5203,
      "step": 12300
    },
    {
      "epoch": 0.8353543519267044,
      "grad_norm": 1.0400761365890503,
      "learning_rate": 9.151134066921177e-05,
      "loss": 2.516,
      "step": 12400
    },
    {
      "epoch": 0.8420910805712746,
      "grad_norm": 1.0561853647232056,
      "learning_rate": 8.77685455498166e-05,
      "loss": 2.5165,
      "step": 12500
    },
    {
      "epoch": 0.8488278092158448,
      "grad_norm": 1.0046792030334473,
      "learning_rate": 8.402575043042144e-05,
      "loss": 2.5207,
      "step": 12600
    },
    {
      "epoch": 0.855564537860415,
      "grad_norm": 1.0624157190322876,
      "learning_rate": 8.028295531102628e-05,
      "loss": 2.5226,
      "step": 12700
    },
    {
      "epoch": 0.8623012665049852,
      "grad_norm": 1.0525325536727905,
      "learning_rate": 7.654016019163111e-05,
      "loss": 2.5107,
      "step": 12800
    },
    {
      "epoch": 0.8690379951495554,
      "grad_norm": 1.0368577241897583,
      "learning_rate": 7.279736507223594e-05,
      "loss": 2.5232,
      "step": 12900
    },
    {
      "epoch": 0.8757747237941256,
      "grad_norm": 1.1435469388961792,
      "learning_rate": 6.905456995284078e-05,
      "loss": 2.5084,
      "step": 13000
    },
    {
      "epoch": 0.8825114524386958,
      "grad_norm": 1.0017807483673096,
      "learning_rate": 6.531177483344563e-05,
      "loss": 2.5167,
      "step": 13100
    },
    {
      "epoch": 0.889248181083266,
      "grad_norm": 1.011366367340088,
      "learning_rate": 6.156897971405045e-05,
      "loss": 2.5076,
      "step": 13200
    },
    {
      "epoch": 0.8959849097278362,
      "grad_norm": 1.0837695598602295,
      "learning_rate": 5.782618459465529e-05,
      "loss": 2.5152,
      "step": 13300
    },
    {
      "epoch": 0.9027216383724064,
      "grad_norm": 0.9874879121780396,
      "learning_rate": 5.4083389475260125e-05,
      "loss": 2.5189,
      "step": 13400
    },
    {
      "epoch": 0.9094583670169766,
      "grad_norm": 1.098609209060669,
      "learning_rate": 5.0340594355864956e-05,
      "loss": 2.5065,
      "step": 13500
    },
    {
      "epoch": 0.9161950956615468,
      "grad_norm": 1.0540030002593994,
      "learning_rate": 4.65977992364698e-05,
      "loss": 2.5002,
      "step": 13600
    },
    {
      "epoch": 0.922931824306117,
      "grad_norm": 1.0398756265640259,
      "learning_rate": 4.285500411707463e-05,
      "loss": 2.5059,
      "step": 13700
    },
    {
      "epoch": 0.9296685529506872,
      "grad_norm": 1.0407922267913818,
      "learning_rate": 3.911220899767947e-05,
      "loss": 2.5016,
      "step": 13800
    },
    {
      "epoch": 0.9364052815952574,
      "grad_norm": 1.0502665042877197,
      "learning_rate": 3.5369413878284305e-05,
      "loss": 2.4985,
      "step": 13900
    },
    {
      "epoch": 0.9431420102398276,
      "grad_norm": 1.073449969291687,
      "learning_rate": 3.162661875888914e-05,
      "loss": 2.5037,
      "step": 14000
    },
    {
      "epoch": 0.9498787388843978,
      "grad_norm": 1.0807173252105713,
      "learning_rate": 2.7883823639493973e-05,
      "loss": 2.4978,
      "step": 14100
    },
    {
      "epoch": 0.956615467528968,
      "grad_norm": 1.0953333377838135,
      "learning_rate": 2.414102852009881e-05,
      "loss": 2.5052,
      "step": 14200
    },
    {
      "epoch": 0.9633521961735382,
      "grad_norm": 1.0280425548553467,
      "learning_rate": 2.0398233400703644e-05,
      "loss": 2.5036,
      "step": 14300
    },
    {
      "epoch": 0.9700889248181084,
      "grad_norm": 1.0233962535858154,
      "learning_rate": 1.6655438281308482e-05,
      "loss": 2.4992,
      "step": 14400
    },
    {
      "epoch": 0.9768256534626786,
      "grad_norm": 0.990680992603302,
      "learning_rate": 1.2912643161913318e-05,
      "loss": 2.5033,
      "step": 14500
    },
    {
      "epoch": 0.9835623821072487,
      "grad_norm": 1.0061684846878052,
      "learning_rate": 9.169848042518152e-06,
      "loss": 2.5027,
      "step": 14600
    },
    {
      "epoch": 0.9902991107518189,
      "grad_norm": 1.0240296125411987,
      "learning_rate": 5.427052923122989e-06,
      "loss": 2.499,
      "step": 14700
    },
    {
      "epoch": 0.9970358393963891,
      "grad_norm": 0.9689468145370483,
      "learning_rate": 1.684257803727824e-06,
      "loss": 2.4925,
      "step": 14800
    },
    {
      "epoch": 1.0,
      "eval_loss": 2.3823723793029785,
      "eval_runtime": 9.2704,
      "eval_samples_per_second": 539.351,
      "eval_steps_per_second": 8.522,
      "step": 14844
    }
  ],
  "logging_steps": 100,
  "max_steps": 14844,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 965640192000000.0,
  "train_batch_size": 64,
  "trial_name": null,
  "trial_params": null
}
